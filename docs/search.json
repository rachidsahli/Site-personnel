[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rachid SAHLI",
    "section": "",
    "text": "Je suis étudiant à l’IUT Paris Rives de Seine en Science des données et alternant à l’INSEE. Au sein de la direction des statistiques démographiques et sociales, mes missions portent sur la couverture de différentes bases de sondage et sur l’appariement de gros volumes de données.\nJ’aime les statistiques, le soleil ☀️, le vélo 🚲 , le cinéma 🎞️ et la programmation 👾."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "À propos",
    "section": "",
    "text": "IUT de Paris - Rives de Seine (Université Paris Cité) | Paris, France\n\n\n\nBachelor universitaire de technologie en Science des données | Sept 2022 - Juin 2025\nCours suivis : Algèbre, Statistique, Probabilités, Programmation, Base de données, Économie"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "L’algorithme des \\(k\\) plus proches voisins\n\n\n\n\n\n\nR\n\n\nMachine learning\n\n\n\nApplication sur R de l’algorithme des \\(k\\) plus proches voisins.\n\n\n\n\n\n29 sept. 2024\n\n\n\n\n\n\nAucun article correspondant"
  },
  {
    "objectID": "blog/knn.html",
    "href": "blog/knn.html",
    "title": "L’algorithme des \\(k\\) plus proches voisins",
    "section": "",
    "text": "1 Introduction\nLe but de l’apprentissage supervisé est de prévoir l’étiquette (classification) \\(Y\\) ou la valeur de \\(Y\\) (régression) associée à une nouvelle entrée \\(X\\), où il est sous-entendu que (\\(X,Y\\)) est une nouvelle réalisation des données, indépendante de l’échantillon observé.\nL’algorithme des \\(k\\) plus proches voisins est une méthode d’apprentissage supervisé. On peut l’utiliser pour classifier quand \\(Y_i\\) est une variable qualitative, les \\(Y_i\\) sont appelés étiquettes. On peut également l’utiliser pour prédire si \\(Y_i \\in \\mathbb{R}\\). C’est donc une régression et les \\(Y_i\\) sont appelés variables à expliquer.\nRemarque : On parle d’apprentissage supervisé car pour chaque \\(X_i\\) de l’échantillon d’apprentissage on dispose de \\(Y_i\\), l’étiquette. Au contraire, on parlera d’apprentissage non-supervisé lorsque l’échantillon est simplement constitué des \\(X_i\\).\n\n\n2 Comment ça marche ?\nEn Classification, pour un nouveau \\(X\\) on classifie son étiquette \\(Y\\) par la méthode des k-plus proches voisins de la façon suivante. On détermine tout d’abord les \\(k\\) plus proches \\(X_i\\) de l’échantillon par rapport à \\(X\\) et on attribue la modalité dominante parmi les k modalités observées (on parle de vote majoritaire).\nEn Régression, pour un nouveau \\(X\\) on prédit la valeur \\(Y\\) par la méthode des k-plus proches voisins de la façon suivante. On détermine tout d’abord les \\(k\\) plus proches \\(X_i\\) de l’échantillon par rapport à \\(X\\) et on calcule la moyenne des \\(Y_i\\).\nRemarque : Pour déterminer les \\(k\\) plus proches \\(X_i\\) de \\(X\\) on utilise généralement la distance euclidienne. Il est possible de pondérer différement certaines composantes de \\(X_i\\) pour lesquelles on veut attribuer plus ou moins d’importance.\nNous allons mettre en pratique ces deux méthodes à travers deux exemples."
  },
  {
    "objectID": "projets.html",
    "href": "projets.html",
    "title": "Projets",
    "section": "",
    "text": "PratiqueR\n\n\n1 min.\n\n\n\nR\n\n\nData Science\n\n\n\nDéveloppement d’un site web interactif fournissant des ressources éducatives et des exercices pratiques pour faciliter l’apprentissage du langage R.\n\n\n\n23 juil. 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProjets BUT SD\n\n\n1 min.\n\n\n\nScience des données\n\n\nStatistique\n\n\nR\n\n\n\nVoici une liste de mes projets réalisées durant mes 3 années à l’institut universitaire de technologie de Paris Rives de Seine ! (2022 - 2025)\n\n\n\n\n\n\n\nAucun article correspondant"
  },
  {
    "objectID": "projets/projets_but/louvre.html",
    "href": "projets/projets_but/louvre.html",
    "title": "Nocturne au musée du Louvre",
    "section": "",
    "text": "Tous les vendredis, le musée du Louvre offre un moment de magie à ses visiteurs au milieu de ses collections. Au programme de ces nocturnes hebdomadaires, de nombreuses activités pour petits et grands. Le 24 novembre 2023, mes camarades de l’IUT et moi avons pu participer à l’une de ces soirées. Nous avons décidé de présenter certains tableaux du célèbre musée au filtre de l’IA. Au moment où cette technologie prend une place active dans notre société, avec par exemple ChatGPT, DALL-E ou encore Mistral AI, il est intéressant de pouvoir approfondir l’utilisation de ces outils permettant de générer des éléments en lien, ici, avec l’art, par exemple. De plus, ce sujet fascinant qu’est l’intelligence artificielle est plus ou moins en lien avec notre formation en science des données. Explorer ce domaine où se mêlent mathématiques, informatique et données était particulièrement captivant.\n\nQu’avons nous fait ?\nL’objectif final était de pouvoir le 23 novembre 2024, présenter une œuvre en rapport avec l’IA au visiteur de la nocturne. Pour cela, 2 mois, auparavant, nous avons décidé de choisir un sujet d’intelligence artificielle qui pouvait coïncider avec une œuvre du musée. Après de longues recherches passionnantes, nous avons choisi de présenter les GAN (Generative adversarial networks). C’est une classe d’algorithmes d’apprentissage non supervisé. Ils permettent de générer des images avec un fort degré de réalisme. Nous avons trouvé la technologie et les méthodes très intéressantes, d’autant plus qu’elles aboutissent à des applications concrètes, telles que la génération d’images artistiques. Cependant, ces algorithmes sont utilisés dans bien d’autres domaines tels que la médecine ou encore la finance. Mais concrètement, comment ça marche ?\n\n\nQu’est-ce qu’un GAN ?\nAfin de comprendre comment il fonctionne, on peut imaginer un jeu entre deux joueurs :\n\nL’artiste (Générateur) : L’objectif du joueur est de créer des images qui se rapprochent le plus de la réalité. Pour cela, il apprend de ses erreurs et réessaie en continu d’obtenir l’œuvre la plus proche du réel.\nLe juge (Discriminateur) : L’objectif de ce joueur est de vérifier si les œuvres réalisées par l’artiste peuvent paraître réelles ou si elles sont encore trop fausses. Pour cela, il compare les œuvres de l’artiste à des œuvres réelles faites par des peintres.\n\nTant que l’image n’est pas accepté par le juge, l’artiste continue à produire des œuvres. Voilà, le fonctionnement d’un GAN ou deux réseaux de neurones se font concurrence. De cette manière, il est possible de créer des images, des vidéos ou d’autres contenues de très bonnes qualités.\n\n\n\n\n\n\n\nSchéma GAN\n\n\n\n\nPrésentation au public\nNous avons décidé de présenter au public le travail d’Obvious. Ce collectif de chercheurs, d’artistes travaille avec des modèles d’apprentissage profond pour explorer le potentiel créatif de l’intelligence artificielle. Ils ont justement utilisé des GAN pour générer une famille de 11 tableaux (la famille Belamy). \nUn portrait a retenu notre attention, le portrait d’Edmond de Belamy. Ce tableau est une impression sur toile qui est rentrée dans l’histoire de l’art moderne. Cela, car c’est la première œuvre d’art produite par un logiciel d’intelligence artificielle à être présentée dans une salle des ventes. Pour couronner le tout, il a été vendu 432 500 dollars chez Christie’s le 25 octobre 2018.  De plus, ce tableau est assez troublant. Il est très difficile à première vue de déterminer qu’une machine a pu en être l’auteur.   Obvious à utiliser un GAN, en l’entraînant sur 15 000 portraits classiques réalisés entre le 14e et 20e siècle. L’algorithme devait donc produire un tableau en sortie qui serait très ressemblant aux portraits classiques. Nous avons décidé de comparer le portrait d’Edmond de Belamy à une œuvre du Louvre se trouvant dans la salle 846 de l’aile Richelieu du musée. C’est une peinture datant du 17e siècle réalisée par Jean Bray, peintre néerlandais. Les tableaux ont quelques points en commun : le fond noir, un homme au centre du tableau, le col blanc avec une veste noir.\n\nPortrait de BelamyPortrait de Jean de Bray\n\n\n\n\n\n\n\n\n\nPortrait d’Edmond de Belamy, Collectif Obvious\n\n\n\n\n\n\n\n\n\n\n\nPortrait d’homme, 1658\n\n\n\n\n\nLes visiteurs étaient agréablement surpris par le réalisme du portrait d’Edmond de Belamy, mais aussi par le prix de vente de l’œuvre. Ils pensaient pouvoir reconnaître la réalisation d’une IA."
  },
  {
    "objectID": "projets/projets_but/louvre.html#quavons-nous-fait",
    "href": "projets/projets_but/louvre.html#quavons-nous-fait",
    "title": "Nocturne au musée du Louvre",
    "section": "Qu’avons nous fait ?",
    "text": "Qu’avons nous fait ?\nL’objectif final était de pouvoir le 23 novembre 2024, présenter une œuvre en rapport avec l’IA au visiteur de la nocturne. Pour cela, 2 mois, auparavant, nous avons décidé de choisir un sujet d’intelligence artificielle qui pouvait coïncider avec une œuvre du musée. Après de longues recherches passionnantes, nous avons choisi de présenter les GAN (Generative adversarial networks). C’est une classe d’algorithmes d’apprentissage non supervisé. Ils permettent de générer des images avec un fort degré de réalisme. Nous avons trouvé la technologie et les méthodes très intéressantes, d’autant plus qu’elles aboutissent à des applications concrètes, telles que la génération d’images artistiques. Cependant, ces algorithmes sont utilisés dans bien d’autres domaines tels que la médecine ou encore la finance. Mais concrètement, comment ça marche ?"
  },
  {
    "objectID": "projets/projets_but/louvre.html#quest-ce-quun-gan",
    "href": "projets/projets_but/louvre.html#quest-ce-quun-gan",
    "title": "Nocturne au musée du Louvre",
    "section": "Qu’est-ce qu’un GAN ?",
    "text": "Qu’est-ce qu’un GAN ?\nAfin de comprendre comment il fonctionne, on peut imaginer un jeu entre deux joueurs :\n\nL’artiste (Générateur) : L’objectif du joueur est de créer des images qui se rapprochent le plus de la réalité. Pour cela, il apprend de ses erreurs et réessaie en continu d’obtenir l’œuvre la plus proche du réel.\nLe juge (Discriminateur) : L’objectif de ce joueur est de vérifier si les œuvres réalisées par l’artiste peuvent paraître réelles ou si elles sont encore trop fausses. Pour cela, il compare les œuvres de l’artiste à des œuvres réelles faites par des peintres.\n\nTant que l’image n’est pas accepté par le juge, l’artiste continue à produire des œuvres. Voilà, le fonctionnement d’un GAN ou deux réseaux de neurones se font concurrence. De cette manière, il est possible de créer des images, des vidéos ou d’autres contenues de très bonnes qualités.\n\n\n\n\n\n\n\nSchéma GAN"
  },
  {
    "objectID": "projets/projets_but/louvre.html#présentation-au-public",
    "href": "projets/projets_but/louvre.html#présentation-au-public",
    "title": "Nocturne au musée du Louvre",
    "section": "Présentation au public",
    "text": "Présentation au public\nNous avons décidé de présenter au public le travail d’Obvious. Ce collectif de chercheurs, d’artistes travaille avec des modèles d’apprentissage profond pour explorer le potentiel créatif de l’intelligence artificielle. Ils ont justement utilisé des GAN pour générer une famille de 11 tableaux (la famille Belamy). \nUn portrait a retenu notre attention, le portrait d’Edmond de Belamy. Ce tableau est une impression sur toile qui est rentrée dans l’histoire de l’art moderne. Cela, car c’est la première œuvre d’art produite par un logiciel d’intelligence artificielle à être présentée dans une salle des ventes. Pour couronner le tout, il a été vendu 432 500 dollars chez Christie’s le 25 octobre 2018.  De plus, ce tableau est assez troublant. Il est très difficile à première vue de déterminer qu’une machine a pu en être l’auteur.   Obvious à utiliser un GAN, en l’entraînant sur 15 000 portraits classiques réalisés entre le 14e et 20e siècle. L’algorithme devait donc produire un tableau en sortie qui serait très ressemblant aux portraits classiques. Nous avons décidé de comparer le portrait d’Edmond de Belamy à une œuvre du Louvre se trouvant dans la salle 846 de l’aile Richelieu du musée. C’est une peinture datant du 17e siècle réalisée par Jean Bray, peintre néerlandais. Les tableaux ont quelques points en commun : le fond noir, un homme au centre du tableau, le col blanc avec une veste noir.\n\nPortrait de BelamyPortrait de Jean de Bray\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPortrait d’homme, 1658\n\n\n\n\n\nLes visiteurs étaient agréablement surpris par le réalisme du portrait d’Edmond de Belamy, mais aussi par le prix de vente de l’œuvre. Ils pensaient pouvoir reconnaître la réalisation d’une IA."
  },
  {
    "objectID": "projets/but_sd.html",
    "href": "projets/but_sd.html",
    "title": "Projets BUT SD",
    "section": "",
    "text": "Intégration de données dans un data warehouse\n\n\n1 min\n\n\n\nSQL\n\n\nBase de données\n\n\n\nConstruction d’une moyen de stockage de données et d’un dashboard pour une entreprise de e-commerce.\n\n\n\nJan 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNocturne au musée du Louvre\n\n\n4 min\n\n\n\nIA\n\n\n\n\n\n\n\nNov 24, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html#formation",
    "href": "about.html#formation",
    "title": "À propos",
    "section": "",
    "text": "IUT de Paris - Rives de Seine (Université Paris Cité) | Paris, France\n\n\n\nBachelor universitaire de technologie en Science des données | Sept 2022 - Juin 2025\nCours suivis : Algèbre, Statistique, Probabilités, Programmation, Base de données, Économie"
  },
  {
    "objectID": "about.html#expérience",
    "href": "about.html#expérience",
    "title": "À propos",
    "section": "Expérience",
    "text": "Expérience\n\n\n\n\n\n\nInstitut national de la statistique et des études économiques (INSEE) | Montrouge, France\n\n\n\nProgrammeur Statistique | 2023 - 2025 Au sein de la Direction des statistiques démographiques et sociales, j’ai mené des travaux d’appariement de données administratives. L’objectif de ces travaux était de mesurer et de comparer la couverture de deux bases de sondages. Par ailleurs, j’ai comparé différents algorithmes d’appariement à l’aide d’analyses statistiques.\nMes missions ont inclus la manipulation de données brutes, le nettoyage des données, l’appariement de grands volumes de données, ainsi que leur analyse statistique."
  },
  {
    "objectID": "about.html#compétences",
    "href": "about.html#compétences",
    "title": "À propos",
    "section": "Compétences",
    "text": "Compétences\n\n\n\n\n\n\nProgrammation\n\n\n\nPython | R | SQL | SAS | GIT\n\n\n\n\n\n\n\n\nLangue\n\n\n\nAnglais (B2) | Espagnol (B2) | Arabe (C2)"
  },
  {
    "objectID": "projets/pratiquer.html",
    "href": "projets/pratiquer.html",
    "title": "PratiqueR",
    "section": "",
    "text": "J’ai créer PratiqueR pour les raisons suivantes :\n- Expliquer les bases du langage R de manière claire et progressive.\n- Illustrer des cas d’utilisation courants à l’aide d’exemples concrets et applicables.\n- Proposer des exercices pratiques pour renforcer vos compétences et faciliter la prise en main."
  },
  {
    "objectID": "projets/projets_but/integration.html",
    "href": "projets/projets_but/integration.html",
    "title": "Intégration de données dans un data warehouse",
    "section": "",
    "text": "Ce projet a été réalisé dans le cadre du cours d’intégration de données en BUT SD (2 ème année).\nL’objectif de ce module était de nous initier au stockage de données en entreprise afin de permettre une approche décisionnelle. Nous avons vu des notions telles que le data warehouse, l’ETL, les systèmes d’information décisionnels, SQL…"
  },
  {
    "objectID": "projets/projets_but/integration.html#introduction",
    "href": "projets/projets_but/integration.html#introduction",
    "title": "Intégration de données dans un data warehouse",
    "section": "Introduction",
    "text": "Introduction\nUne entreprise française de e-commerce nous a sollicités pour analyser le comportement des utilisateurs sur sa plateforme. Dans un premier temps, nous avons équipé l’entreprise d’un système de stockage de données. Ensuite, nous avons mis en place un tableau de bord permettant de répondre à la problématique posée."
  },
  {
    "objectID": "projets/projets_but/integration.html#modèle-relationnel",
    "href": "projets/projets_but/integration.html#modèle-relationnel",
    "title": "Intégration de données dans un data warehouse",
    "section": "Modèle relationnel",
    "text": "Modèle relationnel\nAprès une étude approfondie de l’environnement et des besoins de l’entreprise, nous avons établi un modèle relationnel pertinent, adapté à l’analyse du comportement des utilisateurs sur la plateforme.\nNous avons choisi d’utiliser un modèle relationnel en flocon."
  },
  {
    "objectID": "projets/pratiquer.html#accédez-au-site",
    "href": "projets/pratiquer.html#accédez-au-site",
    "title": "PratiqueR",
    "section": "Accédez au site",
    "text": "Accédez au site\nDécouvrez PratiqueR ici"
  },
  {
    "objectID": "blog/knn.html#prédiction",
    "href": "blog/knn.html#prédiction",
    "title": "L’algorithme des \\(k\\) plus proches voisins",
    "section": "3.1 Prédiction",
    "text": "3.1 Prédiction\nNous allons maintenant manipuler le jeu de données Abalone, disponible ici. Ce dernier contient des informations sur les ormeaux. Ce sont des mollusques marins qui possèdent une seule coquille et qui habitent principalement dans les eaux froides des côtes. La valeur commerciale des ormeaux est étroitement liée à leur âge, qui est le principal critère utilisé pour estimer leur prix. Déterminez l’âge des ormeaux se fait à partir de leurs anneaux (rings). C’est une tâche généralement réalisée en laboratoire qui prend beaucoup de temps. Ainsi, notre objectif est de prédire leur âge (ici la taille de leurs anneaux) à l’aide des variables physiologiques dont nous disposons.\nAfin de pouvoir réaliser notre prédiction nous importons les packages suivants.\n\n# Import library ---------------\nlibrary(kknn)\nlibrary(Metrics)\nlibrary(ggplot2)\n\n\nLe package kknn est une implémentation de l’algorithme des k plus proches voisins. Il permet notamment de pondérer les plus proches voisins lors de la prédiction.\nLe package Metrics est conçu pour évaluer les performances des modèles prédictifs en calculant diverses mesures d’erreur et de précision. Il est particulièrement utile pour les tâches de régression et de classification, car il propose un ensemble de fonctions pour mesurer l’exactitude des prédictions. Nous l’utiliserons pour calculer l’erreur quadratique moyenne.\nLe package ggplot2 permet d’obtenir des visualisations graphiques plus poussées.\n\nEnsuite, nous importons notre jeu de données en nommant les colonnes.\n\n# Import data ---------------\n# Nom des colonnes\ncolnames = c(\"Sex\",\"Length\",\"Diameter\",\"Height\",\"Whole_weight\",\"Shucked_weight\",\n             \"Viscera_weight\",\"Shell_weight\",\"Rings\")\n\n# Import de la table\nabalone &lt;- read.table(\"data_blog/abalone.data\", header = TRUE, sep = \",\", col.names = colnames)\n\nIl contient 4 176 observations et 9 variables. Nous supprimons la variable Sex et les observations pour qui la taille (Height) est égale à 0.\n\n# Longeur du jeu de donnees\ndim(abalone)\n\n[1] 4176    9\n\n# Suppression de la variable Sex\nabalone &lt;- abalone[,-1]\n\n# Suppression des valeurs nul\nabalone &lt;- subset(abalone, Height!=0)\n\n# Aucune valeurs manquantes\nsapply(abalone, function(x) sum(is.na(x)))\n\n        Length       Diameter         Height   Whole_weight Shucked_weight \n             0              0              0              0              0 \nViscera_weight   Shell_weight          Rings \n             0              0              0 \n\n\nCi-dessous, un petit aperçu des données.\n\nhead(abalone, 4)\n\n  Length Diameter Height Whole_weight Shucked_weight Viscera_weight\n1   0.35    0.265  0.090       0.2255         0.0995         0.0485\n2   0.53    0.420  0.135       0.6770         0.2565         0.1415\n3   0.44    0.365  0.125       0.5160         0.2155         0.1140\n4   0.33    0.255  0.080       0.2050         0.0895         0.0395\n  Shell_weight Rings\n1        0.070     7\n2        0.210     9\n3        0.155    10\n4        0.055     7\n\n\n\n3.1.1 Analyse descriptive\nOn procède à une succinte analyse descritpive de notre jeu de données.\n\nsummary(abalone)\n\n     Length          Diameter         Height        Whole_weight   \n Min.   :0.0750   Min.   :0.055   Min.   :0.0100   Min.   :0.0020  \n 1st Qu.:0.4500   1st Qu.:0.350   1st Qu.:0.1150   1st Qu.:0.4421  \n Median :0.5450   Median :0.425   Median :0.1400   Median :0.8000  \n Mean   :0.5241   Mean   :0.408   Mean   :0.1396   Mean   :0.8291  \n 3rd Qu.:0.6150   3rd Qu.:0.480   3rd Qu.:0.1650   3rd Qu.:1.1538  \n Max.   :0.8150   Max.   :0.650   Max.   :1.1300   Max.   :2.8255  \n Shucked_weight   Viscera_weight    Shell_weight        Rings       \n Min.   :0.0010   Min.   :0.0005   Min.   :0.0015   Min.   : 1.000  \n 1st Qu.:0.1861   1st Qu.:0.0935   1st Qu.:0.1300   1st Qu.: 8.000  \n Median :0.3360   Median :0.1710   Median :0.2340   Median : 9.000  \n Mean   :0.3595   Mean   :0.1807   Mean   :0.2389   Mean   : 9.934  \n 3rd Qu.:0.5020   3rd Qu.:0.2530   3rd Qu.:0.3289   3rd Qu.:11.000  \n Max.   :1.4880   Max.   :0.7600   Max.   :1.0050   Max.   :29.000  \n\n\nOn observe ci-dessous la distribution de la variable Rings ainsi que la relation entre la longueur et la taille des ormeaux.\n\nggplot(abalone, aes(x = Rings)) +\n  geom_histogram(fill = \"blue\") +\n  labs(title = \"Distribution de Rings\", y = \"Fréquence\", x = \"Rings\") + \n  theme_minimal()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nggplot(abalone, aes(x = Length, y = Height)) +\n  geom_point(col = \"blue\", pch = 1) +\n  labs(title = \"Relation entre Height et Length\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n3.1.2 Prédicition de la variable Rings\nComme dans la partie précédente, nous commençons par créer deux sous-échantillons distincts (échantillon d’apprentissage et echantillon de test) à partir du jeu de données complet.\n\nN = round((80/100)*nrow(abalone)) # Calcul du nombre d'observations a sélectionner (80 %) \nidx1 &lt;- sample(1:nrow(abalone), size = N, replace = FALSE) # Tirage aleatoire des indices qu'on va sélectionner\ndataL &lt;- abalone[idx1,] # Construction du dataset d'apprentissage\ndataV &lt;- abalone[-idx1,] # Construction du dataset de test ou de validite\n\nA présent, on utilise la fonction kknn() pour mettre en oeuvre notre algorithme de prédiction en fixant \\(k = 3\\).\n\npred &lt;- kknn(Rings ~., dataL, dataV, k = 3, kernel = 'rectangular')\n\nCi-dessous, nous observons nos prédictions en fonction de la variable Rings.\n\nplot(dataV$Rings,pred$fitted.values, xlab = \"Rings\", ylab = \"Prediction\", col = \"blue\")\nabline(0,1, col = \"red\")\n\n\n\n\n\n\n\n\nContrairement à la classification, nous utiliserons l’erreur quadratique moyenne pour mesurer la performance de notre modèle sur l’échantillon de test.\n\nmse &lt;- mse(pred$fitted.values, dataV$Rings)\npaste0(\"Erreur quadratique moyenne = \",mse)\n\n[1] \"Erreur quadratique moyenne = 5.73666001330672\"\n\n\nEnfin, nous allons identifier la valeur de \\(k\\) pour laquelle l’erreur quadratique moyenne est la plus faible. On pourra alors déterminer le niveau optimal de \\(k\\) afin d’améliorer la précision du modèle. La boucle suivante permet de calculer l’erreur quadratique moyenne pour chaque valeur de \\(k\\) sur notre échantillon.\n\nkvec &lt;- 1:100\nerror &lt;- rep(NA, length(kvec))\n\nfor(i in 1:length(kvec)){\n  pred &lt;- kknn(Rings ~., dataL, dataV, k = i, kernel = 'rectangular')\n  error[i] &lt;- mse(dataV$Rings, pred$fitted.values)\n}\n\nOn visualise les résultats sur le graphique ci-dessous.\n\nplot(kvec, error, type = \"b\", col = \"orange\")\nmin_error_niveau &lt;- which.min(error)\nabline(v = kvec[min_error_niveau], col = \"red\", lty = 2)\nlegend(\"topright\", legend = paste(\"Min error at k =\", kvec[min_error_niveau]), col = \"red\", lty = 2)"
  },
  {
    "objectID": "blog/knn.html#analyse-descriptive",
    "href": "blog/knn.html#analyse-descriptive",
    "title": "L’algorithme des \\(k\\) plus proches voisins",
    "section": "4.1 Analyse descriptive",
    "text": "4.1 Analyse descriptive\nOn procède à une succinte analyse descritpive de notre jeu de données.\n\nsummary(abalone)\n\n     Length          Diameter         Height        Whole_weight   \n Min.   :0.0750   Min.   :0.055   Min.   :0.0100   Min.   :0.0020  \n 1st Qu.:0.4500   1st Qu.:0.350   1st Qu.:0.1150   1st Qu.:0.4421  \n Median :0.5450   Median :0.425   Median :0.1400   Median :0.8000  \n Mean   :0.5241   Mean   :0.408   Mean   :0.1396   Mean   :0.8291  \n 3rd Qu.:0.6150   3rd Qu.:0.480   3rd Qu.:0.1650   3rd Qu.:1.1538  \n Max.   :0.8150   Max.   :0.650   Max.   :1.1300   Max.   :2.8255  \n Shucked_weight   Viscera_weight    Shell_weight        Rings       \n Min.   :0.0010   Min.   :0.0005   Min.   :0.0015   Min.   : 1.000  \n 1st Qu.:0.1861   1st Qu.:0.0935   1st Qu.:0.1300   1st Qu.: 8.000  \n Median :0.3360   Median :0.1710   Median :0.2340   Median : 9.000  \n Mean   :0.3595   Mean   :0.1807   Mean   :0.2389   Mean   : 9.934  \n 3rd Qu.:0.5020   3rd Qu.:0.2530   3rd Qu.:0.3289   3rd Qu.:11.000  \n Max.   :1.4880   Max.   :0.7600   Max.   :1.0050   Max.   :29.000  \n\n\nOn observe ci-dessous la distribution de la variable Rings ainsi que la relation entre la longueur et la taille des ormeaux.\n\nggplot(abalone, aes(x = Rings)) +\n  geom_histogram(fill = \"blue\") +\n  labs(title = \"Distribution de Rings\", y = \"Fréquence\", x = \"Rings\") + \n  theme_minimal()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nggplot(abalone, aes(x = Length, y = Height)) +\n  geom_point(col = \"blue\", pch = 1) +\n  labs(title = \"Relation entre Height et Length\") +\n  theme_minimal()"
  },
  {
    "objectID": "blog/knn.html#prédicition-de-la-variable-rings",
    "href": "blog/knn.html#prédicition-de-la-variable-rings",
    "title": "L’algorithme des \\(k\\) plus proches voisins",
    "section": "4.2 Prédicition de la variable Rings",
    "text": "4.2 Prédicition de la variable Rings\nComme dans la partie précédente, nous commençons par créer deux sous-échantillons distincts (échantillon d’apprentissage et echantillon de test) à partir du jeu de données complet.\n\nN = round((80/100)*nrow(abalone)) # Calcul du nombre d'observations a sélectionner (80 %) \nidx1 &lt;- sample(1:nrow(abalone), size = N, replace = FALSE) # Tirage aleatoire des indices qu'on va sélectionner\ndataL &lt;- abalone[idx1,] # Construction du dataset d'apprentissage\ndataV &lt;- abalone[-idx1,] # Construction du dataset de test ou de validite\n\nA présent, on utilise la fonction kknn() pour mettre en oeuvre notre algorithme de prédiction en fixant \\(k = 3\\).\n\npred &lt;- kknn(Rings ~., dataL, dataV, k = 3, kernel = 'rectangular')\n\nCi-dessous, nous observons nos prédictions en fonction de la variable Rings.\n\nplot(dataV$Rings,pred$fitted.values, xlab = \"Rings\", ylab = \"Prediction\", col = \"blue\")\nabline(0,1, col = \"red\")\n\n\n\n\n\n\n\n\nContrairement à la classification, nous utiliserons l’erreur quadratique moyenne pour mesurer la performance de notre modèle sur l’échantillon de test.\n\nmse &lt;- mse(pred$fitted.values, dataV$Rings)\npaste0(\"Erreur quadratique moyenne = \",mse)\n\n[1] \"Erreur quadratique moyenne = 6.17737857618097\"\n\n\nEnfin, nous allons identifier la valeur de \\(k\\) pour laquelle l’erreur quadratique moyenne est la plus faible. On pourra alors déterminer le niveau optimal de \\(k\\) afin d’améliorer la précision du modèle. La boucle suivante permet de calculer l’erreur quadratique moyenne pour chaque valeur de \\(k\\) sur notre échantillon.\n\nkvec &lt;- 1:100\nerror &lt;- rep(NA, length(kvec))\n\nfor(i in 1:length(kvec)){\n  pred &lt;- kknn(Rings ~., dataL, dataV, k = i, kernel = 'rectangular')\n  error[i] &lt;- mse(dataV$Rings, pred$fitted.values)\n}\n\nOn visualise les résultats sur le graphique ci-dessous.\n\nplot(kvec, error, type = \"b\", col = \"orange\")\nmin_error_niveau &lt;- which.min(error)\nabline(v = kvec[min_error_niveau], col = \"red\", lty = 2)\nlegend(\"topright\", legend = paste(\"Erreur min à k =\", kvec[min_error_niveau]), col = \"red\", lty = 2)"
  },
  {
    "objectID": "projets/pratiquer.html#apprendre-r-pas-à-pas",
    "href": "projets/pratiquer.html#apprendre-r-pas-à-pas",
    "title": "PratiqueR",
    "section": "",
    "text": "J’ai créer PratiqueR pour les raisons suivantes :\n- Expliquer les bases du langage R de manière claire et progressive.\n- Illustrer des cas d’utilisation courants à l’aide d’exemples concrets et applicables.\n- Proposer des exercices pratiques pour renforcer vos compétences et faciliter la prise en main."
  },
  {
    "objectID": "projets/pratiquer.html#aperçu-du-site",
    "href": "projets/pratiquer.html#aperçu-du-site",
    "title": "PratiqueR",
    "section": "Aperçu du site",
    "text": "Aperçu du site"
  }
]