[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rachid SAHLI",
    "section": "",
    "text": "Je suis étudiant à l’IUT Paris Rives de Seine en Science des données et alternant à l’INSEE. Au sein de la direction des statistiques démographiques et sociales, mes missions portent sur la couverture de différentes bases de sondage et sur l’appariement de gros volumes de données.\nJ’aime les statistiques, le soleil ☀️, le vélo 🚲 , le cinéma 🎞️ et la programmation 👾."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "L’algorithme des \\(k\\) plus proches voisins\n\n\n\n\n\n\nR\n\n\nMachine learning\n\n\n\nApplication sur R de l’algorithme des \\(k\\) plus proches voisins.\n\n\n\n\n\n29 sept. 2024\n\n\n\n\n\n\nAucun article correspondant"
  },
  {
    "objectID": "blog/knn.html",
    "href": "blog/knn.html",
    "title": "L’algorithme des \\(k\\) plus proches voisins",
    "section": "",
    "text": "1 Introduction\nLe but de l’apprentissage supervisé est de prévoir l’étiquette (classification) \\(Y\\) ou la valeur de \\(Y\\) (régression) associée à une nouvelle entrée \\(X\\), où il est sous-entendu que (\\(X,Y\\)) est une nouvelle réalisation des données, indépendante de l’échantillon observé.\nL’algorithme des \\(k\\) plus proches voisins est une méthode d’apprentissage supervisé. On peut l’utiliser pour classifier quand \\(Y_i\\) est une variable qualitative, les \\(Y_i\\) sont appelés étiquettes. On peut également l’utiliser pour prédire si \\(Y_i \\in \\mathbb{R}\\). C’est donc une régression et les \\(Y_i\\) sont appelés variables à expliquer.\nRemarque : On parle d’apprentissage supervisé car pour chaque \\(X_i\\) de l’échantillon d’apprentissage on dispose de \\(Y_i\\), l’étiquette. Au contraire, on parlera d’apprentissage non-supervisé lorsque l’échantillon est simplement constitué des \\(X_i\\).\n\n\n2 Comment ça marche ?\nEn Classification, pour un nouveau \\(X\\) on classifie son étiquette \\(Y\\) par la méthode des k-plus proches voisins de la façon suivante. On détermine tout d’abord les \\(k\\) plus proches \\(X_i\\) de l’échantillon par rapport à \\(X\\) et on attribue la modalité dominante parmi les k modalités observées (on parle de vote majoritaire).\nEn Régression, pour un nouveau \\(X\\) on prédit la valeur \\(Y\\) par la méthode des k-plus proches voisins de la façon suivante. On détermine tout d’abord les \\(k\\) plus proches \\(X_i\\) de l’échantillon par rapport à \\(X\\) et on calcule la moyenne des \\(Y_i\\).\nRemarque : Pour déterminer les \\(k\\) plus proches \\(X_i\\) de \\(X\\) on utilise généralement la distance euclidienne. Il est possible de pondérer différement certaines composantes de \\(X_i\\) pour lesquelles on veut attribuer plus ou moins d’importance.\nNous allons mettre en pratique ces deux méthodes à travers deux exemples."
  },
  {
    "objectID": "projets.html",
    "href": "projets.html",
    "title": "Projets",
    "section": "",
    "text": "Aucun article correspondant"
  }
]